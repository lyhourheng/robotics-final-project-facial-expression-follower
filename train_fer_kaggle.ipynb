{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dcb879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress TensorFlow warnings for cleaner output\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Suppress INFO and WARNING messages\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'  # Disable oneDNN custom operations\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úì Environment configured - warnings suppressed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b76aba",
   "metadata": {},
   "source": [
    "# üé≠ Facial Expression Recognition (FER) - Kaggle Training\n",
    "\n",
    "This notebook trains a **MobileNetV2-based FER classifier** for the Robotics Final Project.\n",
    "\n",
    "## üìã Project: Facial Expression Follower Robot\n",
    "\n",
    "**Goal:** Classify facial expressions into 5 emotions for robot control\n",
    "- **Happy** ‚Üí Robot moves forward\n",
    "- **Sad** ‚Üí Robot turns right  \n",
    "- **Angry** ‚Üí Robot moves backward\n",
    "- **Surprised** ‚Üí Robot turns left\n",
    "- **Neutral** ‚Üí Robot stops\n",
    "\n",
    "## üîß Setup Instructions\n",
    "\n",
    "### **On Kaggle:**\n",
    "1. **Enable GPU Accelerator**\n",
    "   - Settings ‚Üí Accelerator ‚Üí **GPU T4 x2** (recommended)\n",
    "   - Or **GPU P100** for faster training\n",
    "   \n",
    "2. **Add FER2013 Dataset**\n",
    "   - Add Data ‚Üí Search \"FER2013\"\n",
    "   - Use: `msambare/fer2013` (organized folders)\n",
    "   \n",
    "3. **Internet Access**\n",
    "   - Enable for downloading MobileNetV2 weights\n",
    "\n",
    "### **After Training:**\n",
    "Download these files to your local project:\n",
    "- `fer_classifier.h5`\n",
    "- `fer_classifier_fp16.tflite`\n",
    "- `training_history.png`\n",
    "- `confusion_matrix.png`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8289028",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Setup Environment & Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496d67a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Check GPU availability\n",
    "print(\"=\"*60)\n",
    "print(\"GPU/TPU CHECK\")\n",
    "print(\"=\"*60)\n",
    "print(f\"TensorFlow Version: {tf.__version__}\")\n",
    "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")\n",
    "print(f\"Built with CUDA: {tf.test.is_built_with_cuda()}\")\n",
    "\n",
    "# Get GPU details\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        print(f\"\\n‚úì GPU Detected: {gpu}\")\n",
    "        # Get GPU memory info\n",
    "        try:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            print(\"  Memory growth enabled\")\n",
    "        except:\n",
    "            pass\n",
    "else:\n",
    "    print(\"\\n‚ö† No GPU found - training will be slower on CPU\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bab9a11",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55f48c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Learning\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "\n",
    "# Data Processing\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from pathlib import Path\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"‚úì All libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce068f7",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Configuration & Dataset Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d4a539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============== CONFIGURATION ==============\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 1e-4\n",
    "NUM_CLASSES = 5\n",
    "\n",
    "# Class names for 5 emotions (ONLY direct matches from FER2013)\n",
    "CLASS_NAMES = ['angry', 'happy', 'neutral', 'sad', 'surprised']\n",
    "\n",
    "# Original FER2013 class mapping (0-6):\n",
    "# 0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral\n",
    "# We will ONLY use: Angry(0), Happy(3), Sad(4), Surprise(5), Neutral(6)\n",
    "# EXCLUDED: Disgust(1), Fear(2) - dropped to avoid confusion\n",
    "\n",
    "# Kaggle dataset path (adjust if needed)\n",
    "DATA_DIR = '/kaggle/input/fer2013/fer2013'\n",
    "\n",
    "# Output directory\n",
    "OUTPUT_DIR = '/kaggle/working'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"CONFIGURATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Image Size: {IMG_SIZE}x{IMG_SIZE}\")\n",
    "print(f\"Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"Epochs: {EPOCHS}\")\n",
    "print(f\"Learning Rate: {LEARNING_RATE}\")\n",
    "print(f\"Number of Classes: {NUM_CLASSES}\")\n",
    "print(f\"Classes: {CLASS_NAMES}\")\n",
    "print(f\"‚ö†Ô∏è  EXCLUDING: Disgust and Fear (poor quality/confusion)\")\n",
    "print(f\"Dataset Path: {DATA_DIR}\")\n",
    "print(f\"Output Directory: {OUTPUT_DIR}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12059b08",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Load and Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a7809e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if dataset exists\n",
    "train_dir = os.path.join(DATA_DIR, 'train')\n",
    "test_dir = os.path.join(DATA_DIR, 'test')\n",
    "\n",
    "print(\"Checking dataset structure...\")\n",
    "print(f\"Train directory: {train_dir}\")\n",
    "print(f\"Test directory: {test_dir}\")\n",
    "print(f\"Train exists: {os.path.exists(train_dir)}\")\n",
    "print(f\"Test exists: {os.path.exists(test_dir)}\")\n",
    "\n",
    "# List available classes\n",
    "if os.path.exists(train_dir):\n",
    "    available_classes = sorted(os.listdir(train_dir))\n",
    "    print(f\"\\nAvailable classes in dataset: {available_classes}\")\n",
    "    \n",
    "    # Count samples per class\n",
    "    print(\"\\nClass distribution (Training set):\")\n",
    "    for class_name in available_classes:\n",
    "        class_path = os.path.join(train_dir, class_name)\n",
    "        if os.path.isdir(class_path):\n",
    "            count = len(os.listdir(class_path))\n",
    "            print(f\"  {class_name}: {count} images\")\n",
    "else:\n",
    "    print(\"‚ö† Dataset not found! Make sure you've added the FER2013 dataset in Kaggle.\")\n",
    "    print(\"  Go to: Add Data ‚Üí Search 'FER2013' ‚Üí Add 'msambare/fer2013'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093f920d",
   "metadata": {},
   "source": [
    "### Visualize Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb2c54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "# Display sample images from each class (only the 5 we're using)\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "axes = axes.flatten()\n",
    "\n",
    "CLASSES_TO_VISUALIZE = ['angry', 'happy', 'neutral', 'sad', 'surprised']\n",
    "\n",
    "for idx, class_name in enumerate(CLASSES_TO_VISUALIZE):\n",
    "    class_path = os.path.join(train_dir, class_name)\n",
    "    if os.path.exists(class_path):\n",
    "        # Get first image\n",
    "        img_files = os.listdir(class_path)\n",
    "        if img_files:\n",
    "            img_path = os.path.join(class_path, img_files[0])\n",
    "            img = Image.open(img_path)\n",
    "            \n",
    "            axes[idx].imshow(img, cmap='gray')\n",
    "            axes[idx].set_title(f'{class_name.capitalize()}', fontsize=12, fontweight='bold')\n",
    "            axes[idx].axis('off')\n",
    "            \n",
    "            # Show another sample\n",
    "            if len(img_files) > 1:\n",
    "                img_path2 = os.path.join(class_path, img_files[1])\n",
    "                img2 = Image.open(img_path2)\n",
    "                axes[idx + 5].imshow(img2, cmap='gray')\n",
    "                axes[idx + 5].set_title(f'{class_name.capitalize()} (2)', fontsize=12)\n",
    "                axes[idx + 5].axis('off')\n",
    "\n",
    "plt.suptitle('Sample Images - 5 Direct-Match Classes Only (Excluding Fear & Disgust)', \n",
    "             fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee00ebeb",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Data Preprocessing & Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a078b4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data: with augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.1  # Use 10% for validation\n",
    ")\n",
    "\n",
    "# Test data: only rescale\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# IMPORTANT: Only use the 5 matching classes\n",
    "# Exclude 'disgust' and 'fear' folders if they exist\n",
    "CLASSES_TO_USE = ['angry', 'happy', 'neutral', 'sad', 'surprised']\n",
    "\n",
    "# Create data generators with class filtering\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    classes=CLASSES_TO_USE,  # Only load these 5 classes\n",
    "    subset='training',\n",
    "    shuffle=True,\n",
    "    color_mode='rgb'  # Convert grayscale to RGB for MobileNetV2\n",
    ")\n",
    "\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    classes=CLASSES_TO_USE,  # Only load these 5 classes\n",
    "    subset='validation',\n",
    "    shuffle=False,\n",
    "    color_mode='rgb'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    classes=CLASSES_TO_USE,  # Only load these 5 classes\n",
    "    shuffle=False,\n",
    "    color_mode='rgb'\n",
    ")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"DATA GENERATORS CREATED\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Training samples: {train_generator.samples}\")\n",
    "print(f\"Validation samples: {val_generator.samples}\")\n",
    "print(f\"Test samples: {test_generator.samples}\")\n",
    "print(f\"Class indices: {train_generator.class_indices}\")\n",
    "print(f\"‚úì Using only 5 classes: {CLASSES_TO_USE}\")\n",
    "print(f\"‚úó Excluded: disgust, fear\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5c83e9",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Build MobileNetV2 FER Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ef0977",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_fer_model(num_classes=5, img_size=224):\n",
    "    \"\"\"\n",
    "    Build MobileNetV2-based FER classifier.\n",
    "    \n",
    "    Architecture:\n",
    "    - MobileNetV2 backbone (ImageNet pretrained, frozen initially)\n",
    "    - Global Average Pooling\n",
    "    - Dense(128) + ReLU + Dropout(0.3)\n",
    "    - Dense(num_classes) + Softmax\n",
    "    \"\"\"\n",
    "    # Load pretrained MobileNetV2 (without top classification layer)\n",
    "    base_model = MobileNetV2(\n",
    "        input_shape=(img_size, img_size, 3),\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    \n",
    "    # Freeze base model initially\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # Build model\n",
    "    inputs = keras.Input(shape=(img_size, img_size, 3))\n",
    "    \n",
    "    # Preprocessing for MobileNetV2 (normalize to [-1, 1])\n",
    "    x = keras.applications.mobilenet_v2.preprocess_input(inputs)\n",
    "    \n",
    "    # Extract features\n",
    "    x = base_model(x, training=False)\n",
    "    \n",
    "    # Classifier head\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(128, activation='relu', name='fc1')(x)\n",
    "    x = layers.Dropout(0.3, name='dropout')(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax', name='predictions')(x)\n",
    "    \n",
    "    model = keras.Model(inputs, outputs, name='FER_MobileNetV2')\n",
    "    \n",
    "    return model, base_model\n",
    "\n",
    "# Build model\n",
    "print(\"Building model...\")\n",
    "model, base_model = build_fer_model(NUM_CLASSES, IMG_SIZE)\n",
    "\n",
    "# Display architecture\n",
    "model.summary()\n",
    "\n",
    "print(f\"\\n‚úì Model built successfully!\")\n",
    "print(f\"Total parameters: {model.count_params():,}\")\n",
    "print(f\"Trainable parameters: {sum([tf.size(w).numpy() for w in model.trainable_weights]):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc18180",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60870940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', keras.metrics.TopKCategoricalAccuracy(k=2, name='top2_acc')]\n",
    ")\n",
    "\n",
    "print(\"‚úì Model compiled successfully\")\n",
    "print(f\"Optimizer: Adam (lr={LEARNING_RATE})\")\n",
    "print(f\"Loss: Categorical Crossentropy\")\n",
    "print(f\"Metrics: Accuracy, Top-2 Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e616c2a5",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Setup Training Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c2f67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    # Save best model\n",
    "    ModelCheckpoint(\n",
    "        os.path.join(OUTPUT_DIR, 'fer_best.h5'),\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1,\n",
    "        mode='max'\n",
    "    ),\n",
    "    \n",
    "    # Early stopping to prevent overfitting\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    # Reduce learning rate when stuck\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    # Log training history\n",
    "    CSVLogger(\n",
    "        os.path.join(OUTPUT_DIR, 'training_log.csv'),\n",
    "        separator=',',\n",
    "        append=False\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"‚úì Callbacks configured:\")\n",
    "print(\"  - ModelCheckpoint: Save best model\")\n",
    "print(\"  - EarlyStopping: Patience=10 epochs\")\n",
    "print(\"  - ReduceLROnPlateau: Factor=0.5, Patience=5\")\n",
    "print(\"  - CSVLogger: Log metrics to CSV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb84183",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Train Model (Frozen Base)\n",
    "\n",
    "Training in two stages:\n",
    "1. **Stage 1**: Train only the classifier head (base frozen) - Fast initial learning\n",
    "2. **Stage 2**: Fine-tune top layers (unfreeze some base layers) - Better accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2008f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"STAGE 1: TRAINING WITH FROZEN BASE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Train with frozen base\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n‚úì Stage 1 training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50608ffa",
   "metadata": {},
   "source": [
    "## üîü Fine-Tune Model (Unfreeze Top Layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b773f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"STAGE 2: FINE-TUNING (UNFREEZING TOP LAYERS)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Unfreeze the base model\n",
    "base_model.trainable = True\n",
    "\n",
    "# Freeze early layers, unfreeze top layers\n",
    "for layer in base_model.layers[:100]:\n",
    "    layer.trainable = False\n",
    "\n",
    "print(f\"Total layers: {len(base_model.layers)}\")\n",
    "print(f\"Trainable layers: {sum([l.trainable for l in base_model.layers])}\")\n",
    "\n",
    "# Recompile with lower learning rate\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE/10),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(f\"‚úì Model recompiled with lr={LEARNING_RATE/10}\")\n",
    "\n",
    "# Fine-tune for additional epochs\n",
    "FINETUNE_EPOCHS = 20\n",
    "\n",
    "history_ft = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=FINETUNE_EPOCHS,\n",
    "    callbacks=[\n",
    "        ModelCheckpoint(\n",
    "            os.path.join(OUTPUT_DIR, 'fer_finetuned.h5'),\n",
    "            monitor='val_accuracy',\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-7)\n",
    "    ],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n‚úì Stage 2 fine-tuning complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723c2b49",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£1Ô∏è‚É£ Visualize Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6189a1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history, title_prefix='Stage 1'):\n",
    "    \"\"\"Plot training and validation metrics.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Accuracy\n",
    "    axes[0].plot(history.history['accuracy'], label='Train', linewidth=2)\n",
    "    axes[0].plot(history.history['val_accuracy'], label='Validation', linewidth=2)\n",
    "    axes[0].set_title(f'{title_prefix} - Accuracy', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "    axes[0].set_ylabel('Accuracy', fontsize=12)\n",
    "    axes[0].legend(fontsize=11)\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Loss\n",
    "    axes[1].plot(history.history['loss'], label='Train', linewidth=2)\n",
    "    axes[1].plot(history.history['val_loss'], label='Validation', linewidth=2)\n",
    "    axes[1].set_title(f'{title_prefix} - Loss', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "    axes[1].set_ylabel('Loss', fontsize=12)\n",
    "    axes[1].legend(fontsize=11)\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Plot Stage 1\n",
    "fig1 = plot_training_history(history, 'Stage 1: Frozen Base')\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, 'training_history_stage1.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Plot Stage 2\n",
    "fig2 = plot_training_history(history_ft, 'Stage 2: Fine-Tuning')\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, 'training_history_stage2.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Training history plots saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7111f98",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£2Ô∏è‚É£ Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e1b30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"EVALUATING ON TEST SET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get predictions\n",
    "y_pred_probs = model.predict(test_generator, verbose=1)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "y_true = test_generator.classes\n",
    "\n",
    "# Get class names in correct order\n",
    "class_names_ordered = [k for k, v in sorted(test_generator.class_indices.items(), key=lambda x: x[1])]\n",
    "\n",
    "# Classification report\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(y_true, y_pred, target_names=class_names_ordered, digits=4))\n",
    "\n",
    "# Overall metrics\n",
    "accuracy = np.mean(y_pred == y_true)\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"OVERALL TEST ACCURACY: {accuracy*100:.2f}%\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac5f294",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f97375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    cm, \n",
    "    annot=True, \n",
    "    fmt='d', \n",
    "    cmap='Blues',\n",
    "    xticklabels=class_names_ordered,\n",
    "    yticklabels=class_names_ordered,\n",
    "    cbar_kws={'label': 'Count'}\n",
    ")\n",
    "plt.title('Confusion Matrix - FER Classifier', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.ylabel('True Label', fontsize=13, fontweight='bold')\n",
    "plt.xlabel('Predicted Label', fontsize=13, fontweight='bold')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, 'confusion_matrix.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Confusion matrix saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5be1f2",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£3Ô∏è‚É£ Save Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741a4420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final Keras model\n",
    "final_model_path = os.path.join(OUTPUT_DIR, 'fer_classifier.h5')\n",
    "model.save(final_model_path)\n",
    "print(f\"‚úì Keras model saved: {final_model_path}\")\n",
    "\n",
    "# Get file size\n",
    "size_mb = os.path.getsize(final_model_path) / (1024 * 1024)\n",
    "print(f\"  File size: {size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d37bc6",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£4Ô∏è‚É£ Export to TensorFlow Lite (for Raspberry Pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7daf1d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"EXPORTING TO TENSORFLOW LITE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Convert to TFLite with float16 quantization (smaller, faster)\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_types = [tf.float16]\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save TFLite model\n",
    "tflite_path = os.path.join(OUTPUT_DIR, 'fer_classifier_fp16.tflite')\n",
    "with open(tflite_path, 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "size_mb = os.path.getsize(tflite_path) / (1024 * 1024)\n",
    "print(f\"‚úì TFLite model (FP16) saved: {tflite_path}\")\n",
    "print(f\"  File size: {size_mb:.2f} MB\")\n",
    "\n",
    "# Also save full precision version\n",
    "converter_full = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_full = converter_full.convert()\n",
    "\n",
    "tflite_full_path = os.path.join(OUTPUT_DIR, 'fer_classifier.tflite')\n",
    "with open(tflite_full_path, 'wb') as f:\n",
    "    f.write(tflite_full)\n",
    "\n",
    "size_full_mb = os.path.getsize(tflite_full_path) / (1024 * 1024)\n",
    "print(f\"‚úì TFLite model (FP32) saved: {tflite_full_path}\")\n",
    "print(f\"  File size: {size_full_mb:.2f} MB\")\n",
    "\n",
    "print(\"\\nüìå Use FP16 version for Raspberry Pi deployment!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a393147",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£5Ô∏è‚É£ Test TFLite Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cdd124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TFLite model\n",
    "interpreter = tf.lite.Interpreter(model_path=tflite_path)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input/output details\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "print(\"TFLite Model Details:\")\n",
    "print(f\"  Input shape: {input_details[0]['shape']}\")\n",
    "print(f\"  Input dtype: {input_details[0]['dtype']}\")\n",
    "print(f\"  Output shape: {output_details[0]['shape']}\")\n",
    "\n",
    "# Test with random input\n",
    "test_input = np.random.rand(1, IMG_SIZE, IMG_SIZE, 3).astype(np.float32)\n",
    "interpreter.set_tensor(input_details[0]['index'], test_input)\n",
    "interpreter.invoke()\n",
    "output = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "print(f\"\\n‚úì TFLite inference test successful!\")\n",
    "print(f\"  Output: {output[0]}\")\n",
    "print(f\"  Predicted class: {CLASS_NAMES[np.argmax(output[0])]}\")\n",
    "print(f\"  Confidence: {np.max(output[0]):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c1dc6e",
   "metadata": {},
   "source": [
    "## üì¶ Summary & Download Instructions\n",
    "\n",
    "### ‚úÖ Training Complete!\n",
    "\n",
    "**Model trained on 5 CLEAN classes (direct matches only):**\n",
    "- ‚úÖ Angry (FER2013 class 0)\n",
    "- ‚úÖ Happy (FER2013 class 3)\n",
    "- ‚úÖ Sad (FER2013 class 4)\n",
    "- ‚úÖ Surprised (FER2013 class 5)\n",
    "- ‚úÖ Neutral (FER2013 class 6)\n",
    "- ‚úó **EXCLUDED**: Fear & Disgust (confusing/rare classes)\n",
    "\n",
    "**Files to Download:**\n",
    "1. `fer_classifier.h5` - Full Keras model (for reference)\n",
    "2. `fer_classifier_fp16.tflite` - **Main model for Raspberry Pi** \n",
    "3. `fer_classifier.tflite` - Full precision TFLite (backup)\n",
    "4. `training_history_stage1.png` - Training plots (stage 1)\n",
    "5. `training_history_stage2.png` - Training plots (stage 2)\n",
    "6. `confusion_matrix.png` - Model evaluation\n",
    "7. `training_log.csv` - Training metrics\n",
    "\n",
    "### üì• How to Download from Kaggle:\n",
    "\n",
    "1. Look at the right sidebar ‚Üí **Output** section\n",
    "2. Click on each file ‚Üí **Download**\n",
    "3. Or click **\"Download All\"** to get everything\n",
    "\n",
    "### üöÄ Next Steps on Your Local Machine:\n",
    "\n",
    "```bash\n",
    "# 1. Create fer_model folder (if not exists)\n",
    "mkdir fer_model\n",
    "\n",
    "# 2. Move downloaded files\n",
    "# Place fer_classifier_fp16.tflite in: fer_model/\n",
    "# Place other files for your report\n",
    "\n",
    "# 3. Test full pipeline\n",
    "python main.py\n",
    "```\n",
    "\n",
    "### üìä Expected Performance:\n",
    "\n",
    "- **Test Accuracy**: **65-75%** (better than 7-class or merged approach!)\n",
    "- **Inference Speed on Pi 4**: ~50-100ms per face\n",
    "- **Overall Pipeline FPS**: 10-15 FPS\n",
    "\n",
    "### üéØ Emotion ‚Üí Robot Action:\n",
    "\n",
    "| Emotion | Robot Action | Index |\n",
    "|---------|--------------|-------|\n",
    "| Angry üò† | Backward ‚Üì | 0 |\n",
    "| Happy üòä | Forward ‚Üë | 1 |\n",
    "| Neutral üòê | Stop ‚ñ† | 2 |\n",
    "| Sad üò¢ | Turn Right ‚Üí | 3 |\n",
    "| Surprised üòÆ | Turn Left ‚Üê | 4 |\n",
    "\n",
    "**Note:** Class order is alphabetical: angry, happy, neutral, sad, surprised\n",
    "\n",
    "---\n",
    "\n",
    "**Great work! Your FER model is ready for deployment! üéâ**\n",
    "\n",
    "**Why this approach is better:**\n",
    "- ‚úÖ Higher accuracy (no confusing classes)\n",
    "- ‚úÖ Better precision per class\n",
    "- ‚úÖ Cleaner training (no noisy labels)\n",
    "- ‚úÖ More reliable robot control"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
